{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Si2xAr4od7An"
   },
   "source": [
    "## Parts of Speech Tagging \n",
    "\n",
    "### Comparison of Methods\n",
    "\n",
    "Let's compare different Parts-Of-Speech (POS) taggers. Python has some popular libraries for Natural Language Processing:\n",
    "\n",
    "- NLTK\n",
    "\n",
    "- spaCy\n",
    "\n",
    "- fastText\n",
    "\n",
    "- gensim\n",
    "\n",
    "Using the Treebank tagged corpus in the NLTK library, we'll compare the accuracy for some of NLTK's and spaCy's taggers, as well as a simple bidirectional LSTM trained using Keras, with a Tensorflow backend on a Google Colab instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8njPfYo4d7At"
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TW7z7Yrfd7Ax",
    "outputId": "3bf508a4-d093-448a-acf8-190aa46820f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer\n",
    "from keras.layers import (Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, \n",
    "                          Embedding, Activation)\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import nltk\n",
    "from nltk import ConfusionMatrix\n",
    "from nltk.corpus import treebank, treebank_chunk\n",
    "from nltk.tag import (UnigramTagger, BigramTagger, RegexpTagger, DefaultTagger,  \n",
    "                      PerceptronTagger)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import spacy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from utils_pos_tagging import (compare_taggers, get_tag_list, apply_tagger, get_performance_dataframe,\n",
    "                               get_spacy_test_sentences, get_spacy_accuracy, flatten_tagged_sentences,\n",
    "                               get_word2index, get_tag2index, sentence2int, tag2int, one_hot_encoding)\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "pgn1bnLod7A_",
    "outputId": "1e5ab48e-41b9-4a5c-c1c9-c5d9a7107159",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /Users/Matt/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to /Users/Matt/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/Matt/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Matt/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')\n",
    "nltk.download('treebank')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kPs7xXFd7BL"
   },
   "source": [
    "### Penn Treebank Documentation\n",
    "\n",
    ">[ PENN TREEBANK SAMPLE ]\n",
    "http://www.cis.upenn.edu/~treebank/home.html\n",
    "\n",
    ">This is a ~5% fragment of Penn Treebank, (C) LDC 1995.  It is made\n",
    "available under fair use for the purposes of illustrating NLTK tools\n",
    "for tokenizing, tagging, chunking and parsing.  This data is for\n",
    "non-commercial use only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "zdeVqEJSd7BN",
    "outputId": "1d94e2d9-b93f-4989-99c2-cf826790cd86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', '``'), ('The', 'DT'), ('real', 'JJ'), ('difference', 'NN'), ('seems', 'VBZ'), ('*-1', '-NONE-'), ('to', 'TO'), ('be', 'VB'), ('that', 'IN'), ('the', 'DT'), ('cash', 'NN'), ('market', 'NN'), ('here', 'RB'), ('...', ':'), ('is', 'VBZ'), ('big', 'JJ'), ('enough', 'RB'), ('*RNR*-2', '-NONE-'), ('and', 'CC'), ('liquid', 'NN'), ('enough', 'RB'), ('*RNR*-2', '-NONE-'), ('that', 'IN'), ('the', 'DT'), ('futures', 'NNS'), ('market', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('having', 'VBG'), ('the', 'DT'), ('same', 'JJ'), ('impact', 'NN'), ('0', '-NONE-'), ('it', 'PRP'), ('does', 'VBZ'), ('*?*', '-NONE-'), ('*T*-3', '-NONE-'), ('in', 'IN'), ('America', 'NNP'), ('.', '.'), (\"''\", \"''\")]\n",
      "Tagged sentences: 3914\n",
      "Tagged words: 100676\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = treebank.tagged_sents()\n",
    "print(random.choice(tagged_sentences))\n",
    "print(\"Tagged sentences:\", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(treebank.tagged_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "JOnWMoTzd7BX",
    "outputId": "5a44f724-4ec0-405b-c3b2-01deeb94c199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN        13166\n",
       "IN         9857\n",
       "NNP        9410\n",
       "DT         8165\n",
       "-NONE-     6592\n",
       "NNS        6047\n",
       "JJ         5834\n",
       ",          4886\n",
       ".          3874\n",
       "CD         3546\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag raw count\n",
    "tag_list = list()\n",
    "for s in tagged_sentences:\n",
    "    tag_list.extend([i[1] for i in s])\n",
    "pd.Series(Counter(tag_list)).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "colab_type": "code",
    "id": "_d7_TTzUd7Bj",
    "outputId": "0ee74a29-413a-4a97-c92c-667ef67f0167",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/streetbees/lib/python3.6/site-packages/nltk/tokenize/regexp.py:130: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return [tok for tok in self._regexp.split(text) if tok]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABUoAAABlCAIAAAAUH06HAAAJMmlDQ1BkZWZhdWx0X3JnYi5pY2MAAEiJlZVnUJNZF8fv8zzphUASQodQQ5EqJYCUEFoo0quoQOidUEVsiLgCK4qINEWQRQEXXJUia0UUC4uCAhZ0gywCyrpxFVFBWXDfGZ33HT+8/5l7z2/+c+bec8/5cAEgiINlwct7YlK6wNvJjhkYFMwE3yiMn5bC8fR0A9/VuxEArcR7ut/P+a4IEZFp/OW4uLxy+SmCdACg7GXWzEpPWeGjy0wPj//CZ1dYsFzgMt9Y4eh/eexLzr8s+pLj681dfhUKABwp+hsO/4b/c++KVDiC9NioyGymT3JUelaYIJKZttIJHpfL9BQkR8UmRH5T8P+V/B2lR2anr0RucsomQWx0TDrzfw41MjA0BF9n8cbrS48hRv9/z2dFX73kegDYcwAg+7564ZUAdO4CQPrRV09tua+UfAA67vAzBJn/eqiVDQ0IgALoQAYoAlWgCXSBETADlsAWOAAX4AF8QRDYAPggBiQCAcgCuWAHKABFYB84CKpALWgATaAVnAad4Dy4Aq6D2+AuGAaPgRBMgpdABN6BBQiCsBAZokEykBKkDulARhAbsoYcIDfIGwqCQqFoKAnKgHKhnVARVApVQXVQE/QLdA66At2EBqGH0Dg0A/0NfYQRmATTYQVYA9aH2TAHdoV94fVwNJwK58D58F64Aq6HT8Id8BX4NjwMC+GX8BwCECLCQJQRXYSNcBEPJBiJQgTIVqQQKUfqkVakG+lD7iFCZBb5gMKgaCgmShdliXJG+aH4qFTUVlQxqgp1AtWB6kXdQ42jRKjPaDJaHq2DtkDz0IHoaHQWugBdjm5Et6OvoYfRk+h3GAyGgWFhzDDOmCBMHGYzphhzGNOGuYwZxExg5rBYrAxWB2uF9cCGYdOxBdhK7EnsJewQdhL7HkfEKeGMcI64YFwSLg9XjmvGXcQN4aZwC3hxvDreAu+Bj8BvwpfgG/Dd+Dv4SfwCQYLAIlgRfAlxhB2ECkIr4RphjPCGSCSqEM2JXsRY4nZiBfEU8QZxnPiBRCVpk7ikEFIGaS/pOOky6SHpDZlM1iDbkoPJ6eS95CbyVfJT8nsxmpieGE8sQmybWLVYh9iQ2CsKnqJO4VA2UHIo5ZQzlDuUWXG8uIY4VzxMfKt4tfg58VHxOQmahKGEh0SiRLFEs8RNiWkqlqpBdaBGUPOpx6hXqRM0hKZK49L4tJ20Bto12iQdQ2fRefQ4ehH9Z/oAXSRJlTSW9JfMlqyWvCApZCAMDQaPkcAoYZxmjDA+SilIcaQipfZItUoNSc1Ly0nbSkdKF0q3SQ9Lf5RhyjjIxMvsl+mUeSKLktWW9ZLNkj0ie012Vo4uZynHlyuUOy33SB6W15b3lt8sf0y+X35OQVHBSSFFoVLhqsKsIkPRVjFOsUzxouKMEk3JWilWqUzpktILpiSTw0xgVjB7mSJleWVn5QzlOuUB5QUVloqfSp5Km8oTVYIqWzVKtUy1R1WkpqTmrpar1qL2SB2vzlaPUT+k3qc+r8HSCNDYrdGpMc2SZvFYOawW1pgmWdNGM1WzXvO+FkaLrRWvdVjrrjasbaIdo12tfUcH1jHVidU5rDO4Cr3KfFXSqvpVo7okXY5upm6L7rgeQ89NL0+vU++Vvpp+sP5+/T79zwYmBgkGDQaPDamGLoZ5ht2GfxtpG/GNqo3uryavdly9bXXX6tfGOsaRxkeMH5jQTNxNdpv0mHwyNTMVmLaazpipmYWa1ZiNsulsT3Yx+4Y52tzOfJv5efMPFqYW6RanLf6y1LWMt2y2nF7DWhO5pmHNhJWKVZhVnZXQmmkdan3UWmijbBNmU2/zzFbVNsK20XaKo8WJ45zkvLIzsBPYtdvNcy24W7iX7RF7J/tC+wEHqoOfQ5XDU0cVx2jHFkeRk4nTZqfLzmhnV+f9zqM8BR6f18QTuZi5bHHpdSW5+rhWuT5z03YTuHW7w+4u7gfcx9aqr01a2+kBPHgeBzyeeLI8Uz1/9cJ4eXpVez33NvTO9e7zofls9Gn2eedr51vi+9hP0y/Dr8ef4h/i3+Q/H2AfUBogDNQP3BJ4O0g2KDaoKxgb7B/cGDy3zmHdwXWTISYhBSEj61nrs9ff3CC7IWHDhY2UjWEbz4SiQwNCm0MXwzzC6sPmwnnhNeEiPpd/iP8ywjaiLGIm0iqyNHIqyiqqNGo62ir6QPRMjE1MecxsLDe2KvZ1nHNcbdx8vEf88filhICEtkRcYmjiuSRqUnxSb7JicnbyYIpOSkGKMNUi9WCqSOAqaEyD0tandaXTlz/F/gzNjF0Z45nWmdWZ77P8s85kS2QnZfdv0t60Z9NUjmPOT5tRm/mbe3KVc3fkjm/hbKnbCm0N39qzTXVb/rbJ7U7bT+wg7Ijf8VueQV5p3tudATu78xXyt+dP7HLa1VIgViAoGN1tubv2B9QPsT8M7Fm9p3LP58KIwltFBkXlRYvF/OJbPxr+WPHj0t6ovQMlpiVH9mH2Je0b2W+z/0SpRGlO6cQB9wMdZcyywrK3BzcevFluXF57iHAo45Cwwq2iq1Ktcl/lYlVM1XC1XXVbjXzNnpr5wxGHh47YHmmtVagtqv14NPbogzqnuo56jfryY5hjmceeN/g39P3E/qmpUbaxqPHT8aTjwhPeJ3qbzJqamuWbS1rgloyWmZMhJ+/+bP9zV6tua10bo63oFDiVcerFL6G/jJx2Pd1zhn2m9az62Zp2WnthB9SxqUPUGdMp7ArqGjzncq6n27K7/Ve9X4+fVz5ffUHyQslFwsX8i0uXci7NXU65PHsl+spEz8aex1cDr97v9eoduOZ67cZ1x+tX+zh9l25Y3Th/0+LmuVvsW523TW939Jv0t/9m8lv7gOlAxx2zO113ze92D64ZvDhkM3Tlnv296/d5928Prx0eHPEbeTAaMip8EPFg+mHCw9ePMh8tPN4+hh4rfCL+pPyp/NP637V+bxOaCi+M24/3P/N59niCP/Hyj7Q/Fifzn5Ofl08pTTVNG02fn3Gcufti3YvJlykvF2YL/pT4s+aV5quzf9n+1S8KFE2+Frxe+rv4jcyb42+N3/bMec49fZf4bmG+8L3M+xMf2B/6PgZ8nFrIWsQuVnzS+tT92fXz2FLi0tI/QiyQvpTNDAsAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAddEVYdFNvZnR3YXJlAEdQTCBHaG9zdHNjcmlwdCA5LjI2WJButwAAIABJREFUeJzt3W9vG0eeJ/CSbCsW7dikN7Qzc5eV2L6ZWcjAHY6Uc9hHMcDWg80A80jUs8PuPiD5BjYkn+3uM9I7b4CcB5t9Ss7TyTxgL6DggD1cxJ57cJCBnR22pcEM4kgTtRxbsh3/4T34RZVy/yk2u5vdTer7QYDI7G6yWF1drF91ddXCaDRiAAAAAAAAADDLFuNOAAAAAAAAAAAEhfAeAAAAAAAAYOYhvAcAAAAAAACYeQjvAQAAAAAAAGYewnsAAAAAAACAmXcx7gQAAAAki2EYhmEwxlRVjTstAAAAAF7h7j0AAMD3Op2Oqqr9fr/f7yuKoihK3CkCAAAA8GQB694DAAAQwzBUVdV1PZPJMMZM07xx4wZ+KAEAAGAm4O49AADAd0zTVBSFYnvGWCaTabfb8SYJAAAAwCPcvQcAAPheoVBQVXVra6tQKMSdFgAAAIAJ4O49AADA93Rdv337drvdVlW1UCj0er24UwQAAADgCe7eAwAAOKNH8TVNwwR7AAAAkHy4ew8AAPCdTqej6zr/p6IopVKJFskDAAAASDiE9wAAAN8ZDofiXHqmafZ6Pdy6BwAAgJlwMe4EAAAAJAvNrmeapqZpjUYD4T0AAADMBDx7DwAA8BbTNGmIvqqqcacFAAAAwCuE9wAAAAAAAAAzD8/eAwAAAAAAAMw8hPcAAAAAAAAAMw9T6wEAwPzTdnf537/Z32eMPXn+/H/9+78zxszT0xevXn399OmrN2+ev3z57cuXb872XFxYWFxYuHThwjuXLt26do0xdvHChStLS4yx1ffe4294bXn5R7du/eD69R+k0/aPzly5Ulhdndo3AwAAAPgOnr0HAIBkMU9O9L09y4vG4eHw4ID+Pj49PT49ZYw9ffHiy+Pjl2/ePHn2jDH24tWrN2/emCcnL9+8YTPi+vJyOpW6trx8cfGt8XSXLlx4d3m5sLIiOXbjzh23TehTAAAAOIcQ3gMAQCDGwYFxeGh9UYjGxRfN01P6++jpU/rj//7+99NOoXc/ef/9/3H79v/8y7/s7+7e//WvR//8z/reHv238/Dhl48fP3r8mO+8fOnSOxcvvnz9+uTbbx3f7dLi4jtLS2/evGGMUfS+uLj48tUrt/0jk8tmlWzWbSv6FAAAAGYUwnsAgPPFMRrX9/d5vC2+aHnFPDn5je3F6L1z8eJ/vnGDMfbk2bOlixcZYxcWF49PTx8/e2bZ88LCwuu3f+Zu37z56vXr5y9ffvXNN/RKcW2tsLKyceeOKgSu9W6Xwnv7p2u7u9R5oe/vG4eHD4XM/C83b/74/fdfvX6dTqXSqdSIMcpqy26idCpVWF09evr06uXLP7h+nTH27vLyj2/d+vL4+Oj09P1r18SdxTPy8vXrJ8+eWXocJnL50qXlpSXLi9cuX97/+mt/byiHPgUAAIBpQ3gPAJBo+t6eeXJiebEvPEn+/Z62wFsSVXrx7uXLFy9c4P988uzZq0kGvWeuXGGMvXr9+snz52N3/ugnP6HPyqRSFAQen56+Ho1+cP36bx89Yozt/elP7y4v63t7x2f3/7nry8tX3nnn1evXj589e/HqFX+d4snCysrXJydPnj37g2n+2+9+R5vyKyvq2tp6LqeurVE6LSThvZ22u0v9I/r+viWFxbU1JZvNpFIbd+7Q9+IBP41uME9PPXYBiJlz4+pViocdg1vNVjzGDqYgQbpv3r9+PZ1KPXt7YMItoXvi8bNnz1++XF5aWr50yXLsjatX//XBA3+fKzelPgXGmCrdCgAAEAuE9wAAYbJHVubp6eDhQ/ueoUfj//3P//yb589fvX7NX1lcWHgjVPKO97clbl27dvksEvvm+fPlS5cuXbjAGPNyd7e4tsb/FoMoMWRS79yhzgsefFKeOEZ6d374w6WLF1++fp1aWvrqm29evHol3rWmAJgH0hSxaw8e9Hd3+bvlstnS+rokpBdNFN5b0NwBkoC/sLJC8XlhddWeEj68YqpdAN7ZO5gci3S4nQX867CzcQqMsR/dumXZ7d3lZd4BxL1//TovtzzrHDn2FgUnJt6OSqnb1vVcTrIVfQoAACCH8B4Azi/HKdwcQxfHICFIbMADgGfffstveF69fDmTSlnGWlNczf850ZPq6VTqR7du8YCfYmP6m26l3rhyhTH2H1999fTFC/lb5VdWeCAqhutiNOIYrLKzLg8+/l8Sw9On/Kd0+vnLly/fvLm0uPjo8eOnL15YosTi2hoFsbdv3lSyWR7z6Ht72oMHg4cPtQcP6NTksll1bW19dVVdW1Nu3pR/R1GQ8N6OIvb+7i4VJPG7U0mQB/xub8gS0wXgncfOAscrzvcdfsd4237rnucGoVLnuCCCW58d34o+BQAAiAXCewCYGf6mcOOCjP51bDrzFvPen/7EX/zx++9b7iU+evz40sXvVyGdtHEv3gZnjN3OZvnhx6enCwsL15eX2dkc8stLS8tLS14+Qhy0LDb9KWCmvz2GmkzoKKEYnsIbt5u39I0ojqIn4Z88f350ckJHWRLPB9hT6KVks5Yo3Tg40B48GOzt9XZ26MB0KlW6e9dHSC8KN7y38xLwWzov/H0Em8EuAO8c6wT7oyvhdhYw21XJXOJn+/B+ewG2sA//4dCnAAAAYyG8B4BpiXEKN8cHbh2fs6X2928fPeK3r69evnxxcdHSZSCmcNK0WRLDoyZyeWnpytkd9SfPn//20SO+oDr/UC+D9sV2tvgRYrg+NrSQ4yeUwifqQ3FMG08M5Tm14zNXrmRSKePwkI9atxxrH2DvFjnwkF578IDeIZ1K8WfpQwlBpx3e2+l7e8bh4eDhQ+Pw0Dg8FMsY7+MIGPDbnYcuAO+CVFlB4mffnQVh5fZs9SkwpxzjgvQpeO/QBABILIT3APCdGKdwEwd+c2OHzhJq4NqH2VtSbklzwFvolmRYmoxPnj9/9/JlezJ4Gjx2EPAPFcN1MROmEUpRhMPb9JRmx+yimJOnjTKB9yDQGaGg0R6vMvcB9m7MkxMaeN8bDHhhK66tbdy5E1ZIL4o+vLcTA359f1+8xPI0kCGbXc/llGx2qhE1ugD8cXz2J4LOAnt1aulSJPZAN+Lz4viLwzn+9Hx/rHv9GfDHSELSp+CYw5zYx2qHPgUACBfCe4BZFeMUbvZWjmPjxjEal9xA1mwBudgOttwmmvQrWJq8ljs8luaXpZkrJswxXGfeBvp6nG1u7PsE531CO8o3fn4pqfb2KA9E/Q2wd8NDeu3BA9474LiOXeiSEN7bSdbkizLgt0MXwLQ5dhY4PpoUboXvu7OAJXKAPfoUCPoUAOYYwnuAKCRhCjeRY7PAsTUwUSPAMrTV/gUtzaOJnn21fBH7V7CMXJWkXGzhiZ0I4hP7XvI8yGxzEZh0Qjvq8uDxlVvTnM5y8AH28pT3d3fFkJ7WsZt2SC9KZnhvJwb88jX5gjyXEQp0ASSKx9UTw+0s8PjYlOOPUQI7CzxCnwJJQi0EcB4gvAdwkNgp3ERTultiafNZWh6W7xvuEHdLy8B7U0A8X+JpEvtKop9tLgJBJrRTstmx0VHoA+wlKKTX9/f55TN2afqpmpXw3mLsmnw84E9USebQBTCjYlk9MUhnQTLLf4im1KcQcFocCcdn9Ii8T8FxnCCHPgU4hxDewzyYoSncRFNqd1p+1O29EtObJc7+K+sv3hMHO1jaiEmbbS4CwSe081jMpjTAXv6JbuvYle7ejbfxPaPhvR0P+KmPJviafLFDF8Dci6WzwN/qid/tNiPXzrQ5NsY4x1aZuNVtUyx9CsylLUfQpwBJhvAeYjDTU7j5/mjvEjVLXFitlrGPryd5trkIhDWh3UQfN9UB9m5CXJp+quYmvLeLYE2+2KELALhYVk/02FnAfK2eCCL0KRAUG+AQ3sN48zeFWwQSO0tcWOZvtrkIhD6hnRdRDrB3I1nHrrS+nswWyRyH93Y84I9yTb7YoQsAfAjSWRDL6omI+qYBfQoElV4yIbyfN+dkCrcIzMoscWE5J7PNRWBKE9p5FP0AezfmyUlvZ2eqS9NP1bkK7+3ENfncAv5YpuiPGLoAYKriWj3RY2dB7KsngihIn4LjRFFckBmjJBwfX+UkvQbMqaOKQyEcC+F9zM7zFG4RmMVZ4sJybmebi8C0J7TzKMYB9m5iXMcudOc8vLfT9/b0vb0ErskXO3QBQEIE6SyIZfVEFPXkcyxUnGPAIm5Fn0IsEN5PBlO4RWwOZokLC2abi1hkE9p5kYQB9hL2dexmNKQXIbwfS1yTzx7wF1ZXk7MmX+zQBQCzCKsnQizQp0B81/MI7z1Z+Nu/nfSQmZjCLbG03d2Nn//cy56xzBIXsbG5Ma+zzcWIQjvxlVAmtPNNrIKiHGDvReXTT3/x+ecs7nXsQtfZ3u7u7GiffBJ3QmaJtrvruCZf/+/+Ds3usXx0ASBjYYZ47CwIZUEEXBowqeT3KRTX1jy2SRDee1LvdumPBE7hNpeMg4P29jaLapa4hOO5MZezzSUT3Y4OMqFduOrdbmQD7CdFwwrmI6SHcPE1+RI7geLMsXQBVO/dQ8bC+SRfPRGXBswEeZ+CZazu7Zs3K/fueXlbhPcAAAAAAAAAM28x7gQAAAAAAAAAQFAI7wEAAAAAAABm3sW4E5AUpmnquq4oiqIo9IqmaYyxTCZTKBT4P4m4G0AoUAKnp1KpGIbBGGu1WpSZ8j3H7iYSzwtjrFAoZDIZj1uTQ1XVRqOhqqrldXnWec9YzjAMwzAsBVjXddM0KXPEHLOnx42mac1m05LbY7l9a3/oqzHhLIuv6LrO9+QX9TxBDZYclguBn4Kx5whghqDOAXCD8P47zWaz1+uZpmkYRiaTMQyj2WzS3/R6s9nUdZ3/BBqG0ev18IsIYUEJnJ5Op8MYq9frpmmO3dPLbhydJsaYaZqmaSqKUq1WS6WSl62J4tbvIM867xnLtdvt+/fvF4tFseFF3QSdTkdRlEqlwhijdli9Xi8UCq1Wa2yfiL/4JNzelnq9/stf/rJYLPKz3G63NU0zDONnP/vZH//4R8v122g06MvOB9RgCcGrHcp80uv12LhzhOAHZgvqHABXIzhTq9VyuVytVhNf6ff7/J/FYpH/PRgMcrlcpOmDeYcSOFWWzAy4m0W/3xdP3ERbk0+eJ5PmGGOsWCwOBgP6Z7vdrtVqvGzXajUxr9rttljsE65cLluyotlstttt+lv8IkdHR7lc7ujoKNL0TRlqsERxvDDHniOAGYI6B8ARnr1/S6lU0nXdywjPQqGgKMqkY0EB5FAC/dE0TVVVypNSqUQjoj2i21Z0eKvVml4io9fpdFRVVVWVjwy3v1KpVCyvRKDRaLTbbfq72WxWq1W3PSuViqIobmlrtVqqgEYTcJJSIfnWqqrW63V63GDSnNna2uqeraJKut2u43iNTCajKMpEBXUmoAabCI1PUVWVxq2Io2DEeqlSqdTr9bA+1Ps5Akg+1DkAdhicb9XpdKiykO9Gw4EwyAdChxI4KV3X6/U6H1xKQZ2u617GXXc6ncFgwHeuVCqapm1sbEw90ZGoVCrdbrfX69HAxUwmQ6PBh8MhLzk+BtgHp6oqjaI0DINiG8nOGxsb3W7XsajX63Ue9mia1u/3+SZ5qZB8a03TFhYWarUaXYO9Xo+GgHr8XhSk0afQh/JyaJomb1n2+/15feAZNZh3GxsbvEux1WrRw0H0z3q9rmkald5er8e7w0Lh8RwBzATUOQAWCO+tqL+81WrZO8sNw+Av9no9L0+EAkwKJXBSzWaz1WrxEJHmSxMbyvJjxY6ATqfjfYo4SVAq3xqlQqGgaVqpVCqVSlSuhsNhEvovtra22u22ruuWW+52/gp5kFKRz+d50FUqlSZ6Qr5arfJPabfb4ngQ/lA0Y8w0TVVVeUfAPEEN5h11OVEfU6FQEPun2Fn3EI09Cbc+kZwjgJmDOgfAAoPzHTQajW63ax82mclkNs4YhpHMKbJgDqAEToQaweIriqJYGspuFEWx/Nh7nEe9UqlI7hXIt0ZpY2ODhifwQYn27IoFDZRgZ7PoSfgbwR6kVFiKxPHxsffPLZVKdKPVMAyaT5Fvoq4Wouv67du35zW4Qg3mBV2V9Xq93+/3+31LYdA0bTgc1ut1Gp8f+nMcbucIYBahzgEQ4e69g0wm02g06vW6pd2ZyWSS0CyeA51Oh24h+sjPIMfOCpTAiVDbV8wrWmXNy7H21oD3wfniuG77GG/5VtFULwcaBs/O4nyPg8yj4TEx3W7Xx5wIQUpFEIqi0DJ43W53a2tLsmelUgl3xHVyoAbzolKpiPN4i0+XUI3Biz09wyI+6BGc2zkCmEWocwBEuHvvjHr4EnL/bf5Uq9X79+/7a1UEOXaGoAR6V61WxRtfpmm2223JbG2iUqkkHtvpdDzezspkMuLZ6Xa7YqeAfKs9/VO9HEzT7PV6pVKJMio5bR0vCxFTc81HWB6kVAREzx1omiYf1e/9SZBZhBpsLHFwB5VPvokWXOD/pKg+9NkxcI5gnqA8w6yjZ0UVRZm0tnc4MO6p+5Oi3+/ncrlcLsdX0RgOh+l0mhbY6Pf7xWIxnU4Xi8VisdjtdmNN7GyjmaX9rRMW5NiEQwkMot1u5/P5Wq1WLpfz+byYP7SyWrFYzOVy+Xye/uarso1Go1qtRsdubm6Wy2X6J1/MzM3R0RG9FS3M02w2vW8VRXA5ULbQ37lcznvmBNnqplwuM8aKxSLPYVoVL51O04JG/Cqgd/aeM/bVB91KhSTlw+GQErO5uUk7b25u+jhBlpRbrl/66HK5PE8L46EGm1S73aZyQuWT6gq6VJvNZj6fF0vv2BqJGwwG9uJNm+TnCGC2oM6BOUMDuNLp9HA4DHjgwmg0Cq/fAWC8er1O90h9jDMMcizMN9M0qdvex91pmsLdy81kxwMLhYJjgZRvJbgcwtLr9QaDgWUYf5BSATBtVD7d1lBA6QUAOFf4ffiAByK8h6gFWWB8Lhcnh/MMl0MoTNOsVCrVahWBEAAAAJxnCO8harqu+37iNMixAAmEyyGIer1+//59xlgul7M8bA8AAABwDiG8BwAAAAAAAJh5mDkfAAAAAAAAYOZh3XsZ8+Skt7PT39397VdfZd99d+vu3dLdu5krV+JOF5wj2u5u87PPzJOTwupq4+OPlZs3404RAIBXxsFB87PP/o9h/PjWreq9e+qdO3GnCADmgXFwYBweMsaMw8PhwcGjx49/++jRl48fP/v224MnTxYXFt6MRpkrV65dvvzBjRs/TKdX33tvPZfLpFKZK1cKq6txJx9gijA43xlF9b/4/HPGWDqV+vGtW4dPnz48PGSMba6vb9y5U7l3L+YkwrzrbG83P/vs4eFhOpX64MaN//eHPzDGNtfX0UQGgOTTdne7Ozv0M/pfP/jg919/fXx6Wlxbq967V7p7N+7UAUCi6Xt75skJY0zf3z96+pT+YIyZJye/2d+XHHj50qVb1649evz4xatXqaWl02+/ddvzv33wwXvvvssYK6ysMMZu37ypZLOMMTSxYNYhvH8LRfW9nZ3j09N0KlW6e3fjzh3eEJFvBQiFeXLS/NWveoPBw8PDXDZbvXev8tFHmStX6CYYFb/8ykr13j30MQFAAtGYo3998IAxVv7oIxp2RDVb5/PPj09Pc9ls4+OPUYMBnFs8eu/v7n73yv4+Y8w4PKR7aXa3rl0bjUbPXr588vw5f/H969f//MaNe3/xFxSc88jcODgo/OM/MsaM+/eNw0Pj8HDw8OH/Hg6/PD7+3cEBP/zi4uLy0pL4hlw6laKb/BT837h6lf5QslmMo4SEQ3jPGGP63l73iy8ooGJn9+cl4/B7OzvdL7745WDAGEunUpWPPtr68EMM9YGAjIOD9vY2NX/dAni34D+O9AIAvKWzvd3e3v7N/j79MjZ++lNL7USPvNG4pFw2W1pft+8DALNO291ljJmnp4OHD+kPGkiv7+0dn546HlJcW2OMZVKp1NLS8enp42fPRqPRl48f/8dXX/F9ctmsks0WVlYswbxbGjZ+/vP8yor+D/9g2USdC/3dXUoY9UVyK3/2Z9dTqQXGFhcWlpeW/u13v5MkWMlmM6kUYwwj/yE5znV4b4nqi2trEz1dz5/MpzifWirVe/fQqweT0vf22tvbNIq1uLbW+PjjsWPDxKH7lY8+QsEDgBhZaqSxQbulIwA1GMCsME9O9L09dvbQO/1hnp4yxixxMsfvhPNgmI+Ev7C4+KenTwcPH9I9dnHg/UTBvKPWZ581er3yRx91/uZv5HvSk/xuAX9xbe29q1dHo1FhdfUPR0fLS0vsbLiBW4dFfmWF6kCM/Ifoncfw3jg46A0G3S++oEokv7Ky9eGHpfV1322L0N8Qzg/HUay+D9+6exe/HAAQGct4okmH3AesAAEgdHzKOu8PvVMczmy3spktmtX39micvD2Ypy6AwsoKDYMPqzFT+fTTX3z+efuv/3rSp4GoF4MyQd/ft4Tx+ZUVJZtVstn1XE7JZgurqzRggXd5yDMNI/9hqs5ReG+enHQ+/5wH4TSwOdwgnAZX+x4OAOdKiLff6bF8fvN/6+5dPNQKAFMlPksfcDYQcfgSZg8FmCq3h94l0bvlRjRjbOPOHcbY2IHo/Jb42GC+sLo6paayeXKi/tM//WZ/f/D3fx9w2LzHgN9xrAFlu/1pBbfxDhj5D0HMf3jvOIR+2o/KOz7Mj4gL2DQfnrfPXIWuJQAInaU/0cvDRN7flmYPxQT7AP64PfQumbKOIkkW+E6yZHx7ZMG8W8L4NHuhf662u0t37PX9fUsme3+4wG3EBEb+gz/zHN5bJsAr3b1bvXcv4n4vTLYPnJeZ84ITZ67CQ60AECIxsJ/SbXZMsA/gRvLQu5cp6ygC5KFgwBg7scG8I8k0e9P4LB7wW8ZE8IB/0pzByH+YyByG98mMqDHZ/nnmY+a84Ho7O+3tbf5Qa/R9WwAwNyJ+SB4T7MM5ZL+F62PKOreH3kNJ26wE8468T7MXOu8zDvjLPYz8B4v5Ce8pgqKonjG2ub6+9eGHsUf1Fphs/7yJfeKoWHoWAGBu8I7CWEYDYYJ9mBs+HnrnU9ZN+tB7QHMQzDvyPc1e6MSA3zw9tecwxd4bd+4Ev+WOkf/n0MyH95MuWZ8QmGx/7iVq4TrxuQCMdwUALyZd6256Yu8nBRjL8tA7OwuiJA+9W+KouAZRz2swbxfiNHuhG7syX4gBvwVG/s+fWQ3vKTxub29TpUnhcVhTlEUJk+3PmenNnBccLR5BV03s7XUASCbLwPjkVGKYYB/iYn/onY9/jv6h94DGhpFzE8w7muo0e+HiZ4oxZp+ov7i2RkWLr8w3pWRg5P8smrHwfo5vemOy/VkXzcx5oehsb3d3dnArDABEMzGtHSbYh9Dx0cv2Ket8PPSeqKg4xnvCiRXlNHvh8rgy37QDfhFG/ifTbIT3dDOBByTz/ch6MqcGBIkZfb5d293t7uzMXLIBIHRi7+RMxMwz0RMBCcEferdEID4eemfJjkMs4R+CeTcxTrMXLssZ970y3/Rg5H8sEh3ex7JkfXJgsv3km4MnQsVbYQkfdAAAoZvSIvbRwAT7wM7iB2abss7HQ++zNYRYfi8XwbxccqbZC524Ml8CA34RRv5PSULDe4rqqcFxzu9gY7L9ZErUzHnBWaYMQCsZYO6J43dmfe1MTLA/r/hD7/YAwPtD7/NxDxDBfLiSPM1e6LTdXbqCprQy35Rg5L9vyQrvMS5dYo7nHZghSZ45LxRiK7l09+4sjkcAALk5GHbkaF6/1xyzT1nn46H3hExZFy4E8xGYoWn2QieuzCcP+JNcwDDy300iwnvL7PGzsrhdXBwn25+/wUVJIz7qOfeD2C2t5Jm+rQcAXG9np/mrX/G73HM5SMcywX7jpz9F9RUjMUxlvh5651PWzfctOLqFg2A+YrM7zV7oaJz82FkYZ+gx4eAj/wsrKzN6uSUivO9sb1f/5V+wJtyk+GT7jDHj/v24kzPnjIOD2/X6zD2bGgR/KHcuH04DOIcqn37a29mZ18BexGcVaZVKqL5iROET/6dl9Cw7m7IOT8/Wu937v/41QzAfudZnn3W/+EL75JP5rhJ9cFx2obi2pn3ySdxJC4GXkf+1v/qr1tZWjIn0LRHhPWPMODhAFeabvrd3zn8Xo2GenJzD2v98fmuAuXTeLufz9n0TiO7eI0wdyzw5MU9OkEuQZOeqlGq7u7NbcSUlvAcAAAAAAAAA3xbjTgAAAAAAAAAABIXwHgAAAAAAAGDmXdQ0TVEURVEcN6uq2mg0VFWNOFnemaap67r4FTRNY4xlMplCoSDfyv9JJPlgYRiGYRiMsUKhkMlkHF8hPjKQdhYTNm2SXFIUZRoZGBdN09rttq7rmUym0+nQV2CMmabZ6/X6/X61Wp20tFPusbNTb5omFQAxZ5J8BYUuSHEi/Go6V/kG4JGmac1ms1AotFqt0N+Z/22/+hx/lSwXr1y9Xtd1fWtrq1Kp+E5kcJVKxTCMVqslT3nA1gWIJEUreLk652JpqFvOmqXpK9/K3K/B5AcdQYRepSStFoolInOj63q9XjdNkzG2tbVVr9ctO9TrdfpEVVUn+jGdjWZ/sVgsFou5XG4wGIxsarWa4+vJUavVcrlcOp0+OjoajUbD4ZC+Tj6fHw6H8q2DwaBYLKbT6eIZt3yw2NzcpKzrdrs8Gfl8Pp1O12o1S/J8ZGCxWJz0kCAkuVSpVKaRgbFot9uUbMvr9KWazWa5XO73+5O+Zy6Xq9VqlIebm5tUAAaDQS6Xy+VylC35fL5cLlMezj3fxYkOt2RpLpeL88sAxEf+QxD6z8TYWktsMOTzedpn0mTQpR1uyn2o1Wpja/sgrYsovsPskBetUMrVvPKSD9E31Km005mi08obw2O3co7XYMTfJTmNbX9VStKkgVavAAALD0lEQVRqoVgiMkdHR0f88KOjo3K53G63LUktl8v8b++/SrPS7Gf0P0pWXIkIiLJYPDdirSHfOnr78vaeD/ZQsNlsWkqPb9H/sElyaUoZGLF+v5/P5+VXmpcGn6jb7W5uboqv8Ot8ZKsv2u32+Wmv+C5Ow+Ewl8vx03R0dMQYizDhAAkScXg/Gldr8YuRX7P9fn+Ow/tR4NYFcJKiFUq5mlcJz4d+vy+5nOVbk3CxJKqxPXarjzeMXiwRmV2/3xc7lY6OjiznulgsihHB2ACBzFCz/7tn7wuFgqIo4riCSqWiqqqqqjQCQdTr9RRFUVVVUZRKpUIjH4iu6/wo2k1RlE6n42Wr/J3lSqWSrutuA9rlW0X2fHCztbXV7XbFV7rdbqlU4v+UZKCqqvV6nUYlue3D9yT8FUkWeX9bR5JcmkYGRqzb7TYaDcvwsIDq9bpYehljjUZjfX3dcedKpUJD0yf9FH7V8LFD9Xrde6mg/alIWLZ6vx4LhUKlUrEPbZLwV5xM01QUhZ+mTCbTbre9fyjAfNA0jS5MVWD/QaRLm65uy1bfP6YiS601HA4tO6iqaqkDPeIpLxQKlqqAvjv9lJRKJXpORzzKR9uDvV2bTTQOM6zWxXyQnIKJiEVr0nI1tqkjKUJjj3W7cMSfXcMwLD/KkgOJruulUomX+Xq93uv1eFL5b2un0+Gf4qUScGtn8vehp2BM0+TvwPcMpYqYiPwalLSZ5Vd3kJyXZ69bQRpb28iFXqVIDnH7Cl5KiG/RR2R2qqqKERk9k2vZR3zFY/s8mmZ/OCjKp2EM9q4LeydQu90Wxxt0u11754Q4LOHo6KjZbHrZ6uWdHVF/yXA4zOfz9mTLt47e7ityywdH4p5unZRuvWiMMb6/vTeIkkQjVcT+p7FZJH9bCUkuTS8Do1QsFofD4ebmJo38cXsUZaIuT3n5tN+k6na7/m5b9ft9PoiIf7Q4ml1eKsQv1Ww2PV6Po9Eol8vxT/F+PY6CFad8Ph/9UEOABJJfcYwx8ddTrO0D/piKrzjWWkHuDtVqtXQ6zVNOVQF/t8FgIA4r7ff7lt9Z/j72qmzkuXVRLpdzuZzHu/dBWhfzZ+wpcOOlaHnPPUlTR16E5MdKLpyjo6N8Ps9HaJbLZfFHWX7F0ag0/qNGBUb87vaGnNsmR4751u/3LS1A8f6k7yrC/ike7957vAYlZcDx6g4350VjC5I80nETepUiOWRsdSopIb7FFZFJ0MVraVWWy2XxByKdTnsZfx1Zsz+4xXq9Tt2xrVbLy73NZrMp7km9YvZeK+p8zWQymUzGftPPcavHd3ZDvXduvfKSrYZh1M94zwfGWLVa5clrt9vVatVjUhlj+XyeJ6ZUKtl7pzRNq1QqrVZL7H8am0Vj31ZOkkvTyMCIVSqVarVqmiblagR91Ra+s0VVVT7bHGPMMh3m2FJB3bGapmmaVigUaMS75f3drlZN0+hzS6XSpPN4+StOuq7fvn273W5TlzN1tAOART6f51er5Z5VwB9T0TQq81KpxFOuKEqr1eKDdCjlvHJTVbXRaPCUj63KmLfWBe3gPcG+Wxfzx8sp8ChI0ZI0deRFyMuxjhdOJpPRdX0wGLRarUqlsr6+Lr6n/Iprt9uNRoNPdaYoSqPR2NjY8P31vaB70Za7tTyFvqsIcSjERFsDXoPEfnVPL+fHFiTH9HgUepXieMjY6lRSQgKKPiJzYxhGqVQS59ImrVar3+9TO7Pf79Od9iAf5CjGaOgiFXTvxcg0TTHgJLdv37a8Ir9+HLd6fGcJmm/T/ibyrZlMhqdn0jF7NKrKMAwaVOz9WMspPz4+tuxANYXlPcdm0di3HUuSh6FnYMT4rPiFQoFGB6nBZractINA/rso12g0ms0m1cv8D54MSamgkWmKovCJSe3f2u1qpYUG+v2+aZqmaYo/k96TPWlxYoxVKhUaMEZjIGmA1kSfCzD3JO2G4D+mXJBay40l5eLgZE3TLD16iqI0m02acn9sVcZcajPxkR/+oROl2V/rYs54PAUeBSlakqaOpAiNPXbshUPBkj0SHvsrbCmW0RSVra0t3lrodrvemw0SdNvJrSUg2Rr8GmROV/f0cn5sQXJMj3ehVyn2Q8Z+BUkJCS7iiMwRVVm9Xs9eJjOZjKZpNGifnlzwEopH2ewP6OKkF5iiKL1ebxodEsHfOZPJNBqNer3uGAy4bc1kMv5+oqiW13W92+1ubW35TLQLXdc7nQ6VS54n08t8TpKHoWdglOw/LcHv3lN3vqXW4Ctk2HW7Xd+1laqqzWaT7jNY1guRl4pKpSJWbZqm9ft9L59I+cMTzJ82nKj4TVqcqIdV7Gunp8UQ3gN4F+IvRZBayyPDMHhSC4WC5Xo3TZMqBN9VGXNqY2maNlHT3F/rYs4EOQV2UypakiI0lvzCoeeTW63WYDCoVCpiLCQ/UFGU6EcLMsYqlUqz2bSvRsaCVRHid7F/L7etwa9BR9PL+SAFyYvQqxT7IWO/gqSEBBdxRGYnie052qTrumEYXk5ulM3+gBYnPcC+eCAN0wqelFDembqC3GYykG/1YWtrq91u00D6sN6T44PzefU0vcwXSXIp9AyMDN39pr9plfvg1XSr1aKxG+Ir/FMsqBYL8qH0FdrttqWykJcKcVyJaZreZ6qjz+L/pMrLxy/lRMVpOByKH0pnar5bzABuqCXB/+n9PkBYvxTBay1HnU5H/F71ep0/2latVsWUU5VFW31XZeztxwEoAT5uqkTcukigIKfAYkpFi0mL0FiSC4fuElerVR7Yi60++RVH90jFX09N08T9La0I8X18VwKENxssOeC7irCkp9vtiiG6ZGso16BdwJyXZG+QguRR6FWK5RAvX8GthBB+c9tfL0mMdWav16MxX7yScXt6gnoBPI5ciLjZH4jjipQ0m7+4DKk4G1mtVqPZKeiPzc1NPvNBrVajdQv5UeKby7fK39kNzRVBKw3SK8PhMJ1O8+VV5FvFVRYdV+Ycy7LGw9gMpJUe0+k0n9Nic3OTCXO90Fb6m6+jKC7P6JhFY9/WXx5GkIGR4YtVihPkjIQ1WsWT5fE9aeaScrnMzwu9LuYbvXMos2sUi0W3GRzdLhz+rcvlMu3Di5P8emw2m/l8ng6hYz2u++i7OI3OViLlH5rL5cJabBJg5lD9b7+u+frAVNvTkj9UD/NjA/6YutVazWZTrConrfNrZ6siFYtFWk8ol8tZpqRqt9titcM/QlKVjSZpXWxubvIaW169BGldzCX5KZAYW7S8lysvTR23IuTlWMcLh7fE6EB6H8YYnx7M7UBL1vGCZ1kQm0ovfwfGGM9Vt0pgNK6hTmhyMscmjY8qYnRW21Bq7RevfKvkGhwbdMgjC985L8nekXtBGlvbuAm9Shl7iNtX4CQlhN6fMZZOp/n8fNP7guEGFMVikZ8dTtyBTrrjVSMXcbPft4XRaOSvX4C6xwqFQuhjxaf3znMDWeQPjUEKPd90XachT9M+HdTF6PYpbqWCvnUmk/HRiUjHMl+PyfkWy4cCJBC/FvxVL0n+pZBUm241QJCqjDFGE5SGPgb1XAl4CiIT8EfE94UjP1Cy1cvlkJz2Nl1KbkdJtk7vGvSd8/LsnYPWSMCvwG/gh52umAV8JCGyZr9v/sN7AIhSr9ejaXvjTggAAAAAACTRxbgTAAAy1Asuzu6LCB8AAAAAAOxw9x4AAAAAAABg5k08cz4AAAAAAAAAJA3CewAAAAAAAICZh/AeAAAAAAAAYOYhvAcAAAAAAACYef8fpuXxs9JqpPEAAAAASUVORK5CYII=",
      "text/plain": [
       "Tree('S', [Tree('NP', [('Pierre', 'NNP'), ('Vinken', 'NNP')]), (',', ','), Tree('NP', [('61', 'CD'), ('years', 'NNS')]), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), Tree('NP', [('the', 'DT'), ('board', 'NN')]), ('as', 'IN'), Tree('NP', [('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD')]), ('.', '.')])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualisation\n",
    "display(treebank_chunk.chunked_sents()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlyWQZDDd7Bv"
   },
   "source": [
    "## NLTK taggers\n",
    "\n",
    "The following built in taggers are tested:\n",
    "\n",
    "- `RegexpTagger`\n",
    "\n",
    "- `DefaultTagger`\n",
    "\n",
    "- `UnigramTagger`\n",
    "\n",
    "- `BigramTagger`\n",
    "\n",
    "- `PerceptronTagger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCeVssmWd7By"
   },
   "outputs": [],
   "source": [
    "# Keeping it simple for now, 80:20 train/test split without random sampling\n",
    "split = int(len(tagged_sentences)*0.2)\n",
    "train_sentences = tagged_sentences[split:]\n",
    "test_sentences = tagged_sentences[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyX2zV9Zd7CA"
   },
   "outputs": [],
   "source": [
    "# some regex patterns from NLTK documentation\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),               # gerunds\n",
    "    (r'.*ed$', 'VBD'),                # simple past\n",
    "    (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),               # modals\n",
    "    (r'.*s$', 'NNS'),                 # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "    (r'.*able$', 'JJ'),               # adjectives\n",
    "    (r'.*ly$', 'RB'),                 # adverbs\n",
    "    (r'.*', 'NN')                     # nouns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAWLym5rd7CO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.81 µs ± 250 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit regexp_tagger = RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtHoiIdnd7CX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794 ns ± 19.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit default_tagger = DefaultTagger('NN') # majority tag by inspection above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JBZoj9qZd7Cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.81 s ± 44.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit unigram_tagger = UnigramTagger(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hN4qFlQAd7Cp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.04 s ± 47.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit bigram_tagger = BigramTagger(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7P510xcWd7Cz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.4 s ± 1.36 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "perceptron_tagger = PerceptronTagger()\n",
    "perceptron_tagger.train(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoipCrild7C7"
   },
   "outputs": [],
   "source": [
    "# training set only\n",
    "regexp_tagger = RegexpTagger(patterns)\n",
    "default_tagger = DefaultTagger('NN') # majority tag by inspection above\n",
    "unigram_tagger = UnigramTagger(train_sentences)\n",
    "bigram_tagger = BigramTagger(train_sentences)\n",
    "perceptron_tagger = PerceptronTagger()\n",
    "perceptron_tagger.train(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2E-Mauccd7DB"
   },
   "source": [
    "## Test set evaluation of NLTK taggers \n",
    "\n",
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pK25FxVJd7DE",
    "outputId": "93758206-0c93-4c7d-8d43-d2abb646c916"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/streetbees/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/streetbees/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "tagger_dict = {\n",
    "    'RegExpTagger': regexp_tagger,\n",
    "    'DefaultTagger': default_tagger,\n",
    "    'UnigramTagger': unigram_tagger,\n",
    "    'BigramTagger': bigram_tagger,\n",
    "    'PerceptronTagger': perceptron_tagger\n",
    "}\n",
    "compare_df = compare_taggers(tagger_dict, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eck0_Qvd7DR",
    "outputId": "07ee7453-08a4-455b-ecc7-33e19e7a9353"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PerceptronTagger</th>\n",
       "      <td>0.965131</td>\n",
       "      <td>0.964966</td>\n",
       "      <td>0.965363</td>\n",
       "      <td>0.965131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UnigramTagger</th>\n",
       "      <td>0.840451</td>\n",
       "      <td>0.853554</td>\n",
       "      <td>0.901197</td>\n",
       "      <td>0.840451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegExpTagger</th>\n",
       "      <td>0.220020</td>\n",
       "      <td>0.127380</td>\n",
       "      <td>0.179654</td>\n",
       "      <td>0.220020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigramTagger</th>\n",
       "      <td>0.186124</td>\n",
       "      <td>0.217920</td>\n",
       "      <td>0.908818</td>\n",
       "      <td>0.186124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DefaultTagger</th>\n",
       "      <td>0.127189</td>\n",
       "      <td>0.028703</td>\n",
       "      <td>0.016177</td>\n",
       "      <td>0.127189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Accuracy        F1  Precision    Recall\n",
       "PerceptronTagger  0.965131  0.964966   0.965363  0.965131\n",
       "UnigramTagger     0.840451  0.853554   0.901197  0.840451\n",
       "RegExpTagger      0.220020  0.127380   0.179654  0.220020\n",
       "BigramTagger      0.186124  0.217920   0.908818  0.186124\n",
       "DefaultTagger     0.127189  0.028703   0.016177  0.127189"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df.sort_values(['Accuracy', 'F1'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XCB6PWI1d7Di"
   },
   "source": [
    "PerceptronTagger **per-token accuracy** on the test set at 0.966 approaches the generally reported 97% figures [1] for state of the art machine learning POS tagging. It may be possible to push the metric further up if the entire Treebank corpus were available to expand the training set, instead of the current ~5% subset, but with diminishing returns of performance gain.\n",
    "\n",
    "It is important to note that a per-token accuracy metric does not reflect adequately the quality of tagging on a sentence level. [2]\n",
    "\n",
    "[1] https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art)\n",
    "\n",
    "[2] https://nlp.stanford.edu/pubs/CICLing2011-manning-tagging.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmVQRKqnd7Dl"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4HFsV5rd7Do",
    "outputId": "f8b43e60-65b8-4870-96a0-8f52c4165ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |                                  -                                    |\n",
      "       |                                  N                                    |\n",
      "       |                                  O                                    |\n",
      "       |             N                    N             N                    V |\n",
      "       |      N      N      I      D      E      J      N                    B |\n",
      "       |      N      P      N      T      -      J      S      ,      .      D |\n",
      "-------+-----------------------------------------------------------------------+\n",
      "    NN | <12.1%>  0.1%   0.0%   0.0%      .   0.3%   0.0%      .      .   0.0% |\n",
      "   NNP |   0.1%  <9.8%>     .   0.0%      .   0.1%   0.0%      .      .      . |\n",
      "    IN |      .      .  <9.9%>  0.0%      .   0.0%      .      .      .      . |\n",
      "    DT |   0.0%      .   0.0%  <8.3%>     .      .      .      .      .      . |\n",
      "-NONE- |      .      .      .      .  <6.4%>     .      .      .      .      . |\n",
      "    JJ |   0.4%   0.1%   0.0%   0.0%      .  <5.4%>  0.0%      .      .   0.0% |\n",
      "   NNS |   0.0%   0.0%      .      .      .   0.0%  <5.9%>     .      .      . |\n",
      "     , |      .   0.0%      .      .      .      .      .  <4.7%>     .      . |\n",
      "     . |      .      .      .      .      .      .      .      .  <4.0%>     . |\n",
      "   VBD |   0.0%      .      .      .      .      .      .      .      .  <3.2%>|\n",
      "-------+-----------------------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Picking the best performing PerceptronTagger as example\n",
    "truth = get_tag_list(test_sentences)\n",
    "preds = get_tag_list(apply_tagger(perceptron_tagger, test_sentences))\n",
    "confusion_matrix = ConfusionMatrix(truth, preds)\n",
    "\n",
    "print(confusion_matrix.pretty_format(show_percents=True, truncate=10, sort_by_count=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMYrTbFqd7Dz"
   },
   "source": [
    "We can also look at the individual metrics for each tag to give a finer grained picture over the weighted average metrics for Precision, Recall and F1-Score calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtrrf_NHd7Dz"
   },
   "outputs": [],
   "source": [
    "test_tag_list = list()\n",
    "for s in test_sentences:\n",
    "    test_tag_list.extend([(i[0], i[1]) for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B99Q0tLbd7D7",
    "outputId": "8bf5855c-d61e-427a-9389-b9dda790d950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perceptron_tagger\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NNP</th>\n",
       "      <td>0.816052</td>\n",
       "      <td>0.966690</td>\n",
       "      <td>0.706031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.999450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>0.969416</td>\n",
       "      <td>0.977570</td>\n",
       "      <td>0.961397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNS</th>\n",
       "      <td>0.921844</td>\n",
       "      <td>0.874525</td>\n",
       "      <td>0.974576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JJ</th>\n",
       "      <td>0.764623</td>\n",
       "      <td>0.887079</td>\n",
       "      <td>0.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.772423</td>\n",
       "      <td>0.639873</td>\n",
       "      <td>0.974235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.991970</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.990746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>0.955495</td>\n",
       "      <td>0.921727</td>\n",
       "      <td>0.991833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBZ</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JJR</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RB</th>\n",
       "      <td>0.804774</td>\n",
       "      <td>0.761290</td>\n",
       "      <td>0.853526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0.990676</td>\n",
       "      <td>0.990676</td>\n",
       "      <td>0.990676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBD</th>\n",
       "      <td>0.765186</td>\n",
       "      <td>0.919390</td>\n",
       "      <td>0.655280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBN</th>\n",
       "      <td>0.671202</td>\n",
       "      <td>0.614108</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-NONE-</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TO</th>\n",
       "      <td>0.998736</td>\n",
       "      <td>0.997475</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRP</th>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.994030</td>\n",
       "      <td>0.959654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBG</th>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.597826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRP$</th>\n",
       "      <td>0.962751</td>\n",
       "      <td>0.928177</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JJS</th>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.878049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VB</th>\n",
       "      <td>0.356913</td>\n",
       "      <td>0.613260</td>\n",
       "      <td>0.251701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>0.870712</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.911602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>``</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBP</th>\n",
       "      <td>0.490798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.325203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>0.949045</td>\n",
       "      <td>0.903030</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WDT</th>\n",
       "      <td>0.534884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.365079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRB</th>\n",
       "      <td>0.983607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNPS</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WP$</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-LRB-</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-RRB-</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBR</th>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              F1  Precision    Recall\n",
       "NNP     0.816052   0.966690  0.706031\n",
       ",       0.999450   1.000000  0.998901\n",
       "CD      0.969416   0.977570  0.961397\n",
       "NNS     0.921844   0.874525  0.974576\n",
       "JJ      0.764623   0.887079  0.671875\n",
       "MD      1.000000   1.000000  1.000000\n",
       "NN      0.772423   0.639873  0.974235\n",
       "DT      0.991970   0.993197  0.990746\n",
       "IN      0.955495   0.921727  0.991833\n",
       ".       1.000000   1.000000  1.000000\n",
       "VBZ     0.823529   1.000000  0.700000\n",
       "JJR     0.641026   0.515464  0.847458\n",
       "RB      0.804774   0.761290  0.853526\n",
       "CC      0.990676   0.990676  0.990676\n",
       "VBD     0.765186   0.919390  0.655280\n",
       "VBN     0.671202   0.614108  0.740000\n",
       "-NONE-  1.000000   1.000000  1.000000\n",
       "TO      0.998736   0.997475  1.000000\n",
       "PRP     0.976540   0.994030  0.959654\n",
       "VBG     0.711207   0.877660  0.597826\n",
       "PRP$    0.962751   0.928177  1.000000\n",
       "JJS     0.867470   0.857143  0.878049\n",
       "VB      0.356913   0.613260  0.251701\n",
       "POS     0.870712   0.833333  0.911602\n",
       "``      1.000000   1.000000  1.000000\n",
       "VBP     0.490798   1.000000  0.325203\n",
       "EX      0.636364   1.000000  0.466667\n",
       "''      0.949045   0.903030  1.000000\n",
       "WP      1.000000   1.000000  1.000000\n",
       ":       1.000000   1.000000  1.000000\n",
       "WDT     0.534884   1.000000  0.365079\n",
       "WRB     0.983607   1.000000  0.967742\n",
       "$       1.000000   1.000000  1.000000\n",
       "LS           NaN   0.000000       NaN\n",
       "NNPS    0.078431   0.068966  0.090909\n",
       "WP$     1.000000   1.000000  1.000000\n",
       "-LRB-   1.000000   1.000000  1.000000\n",
       "-RRB-   1.000000   1.000000  1.000000\n",
       "RBR     0.048780   0.500000  0.025641"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again using the perception tagger as an example\n",
    "# precision, recall, f1 scores for each individual class\n",
    "print('perceptron_tagger')\n",
    "get_performance_dataframe(perceptron_tagger, test_tag_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XyMNnD98d7EE"
   },
   "source": [
    "## spaCy tagger: pretrained ConvNet\n",
    "\n",
    "Loading up `en_core_web_sm` and `en_core_web_md` models for spaCy to use for the POS tagger. \n",
    "\n",
    "From documentation about these models:\n",
    "\n",
    "> English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Assigns word vectors, context-specific token vectors, POS tags, dependency parse and named entities.\n",
    "\n",
    "> OntoNotes Release 5.0 is the final release of the OntoNotes project, a collaborative effort between BBN Technologies, the University of Colorado, the University of Pennsylvania and the University of Southern Californias Information Sciences Institute. The goal of the project was to annotate a large corpus comprising various genres of text (news, conversational telephone speech, weblogs, usenet newsgroups, broadcast, talk shows) in three languages (English, Chinese, and Arabic) with structural information (syntax and predicate argument structure) and shallow semantics (word sense linked to an ontology and coreference).\n",
    "\n",
    "> Common Crawl's web archive consists of petabytes of data collected since 2011. It completes crawls generally every month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPVB8uT8d7EF"
   },
   "outputs": [],
   "source": [
    "# small model\n",
    "sm_nlp = spacy.load('en_core_web_sm')\n",
    "# medium model\n",
    "md_nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kbyo-o1d7EI",
    "outputId": "a3fd1606-ed0e-4bb8-d8c7-76854683fc11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN     2894\n",
       "NNP    2117\n",
       "IN     2109\n",
       "DT     1612\n",
       "NFP    1384\n",
       "NNS    1203\n",
       "JJ     1164\n",
       ",       912\n",
       ".       807\n",
       "CD      691\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspecting top tags using small model\n",
    "sm_doc = sm_nlp(' '.join([i[0] for i in test_tag_list]))\n",
    "pd.Series(Counter([token.tag_ for token in sm_doc])).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJ7lvaRtd7ER"
   },
   "source": [
    "spaCy's pipeline takes care of tokenisation and parsing. However, the results of its tokenisation are different from that of NLTK's, so to arrive at an accuracy figure we can't do a straightforward plug-in to the evaluation functions written for NLTK's taggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fr_yZMNKd7ES",
    "outputId": "539a9cfb-1007-4543-ce55-d2d6443dbb1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements from NLTK tokenisation: 19530\n",
      "Number of elements from spaCy: 20876\n"
     ]
    }
   ],
   "source": [
    "print('Number of elements from NLTK tokenisation:', len(test_tag_list)) \n",
    "print('Number of elements from spaCy:', len([(token.text, token.tag_) for token in sm_doc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4auViF5d7Eh"
   },
   "outputs": [],
   "source": [
    "spacy_test_sentences = get_spacy_test_sentences(test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TskzYTy4d7En"
   },
   "source": [
    "### Accuracy for spaCy tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thCAmdIId7Eo",
    "outputId": "78d72f9d-f5ef-4ebc-f490-136fcfe76a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small model accuracy: 89.5289298515105\n",
      "medium model accuracy: 89.42140296979007\n"
     ]
    }
   ],
   "source": [
    "print(\"small model accuracy:\", get_spacy_accuracy(sm_nlp, spacy_test_sentences))\n",
    "print(\"medium model accuracy:\", get_spacy_accuracy(md_nlp, spacy_test_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BwaHtdVd7Ew"
   },
   "source": [
    "At first glance, it looks as though the accuracy score for spaCy's pretrained small and medium ConvNet English POS tagger models are both poorer than the PerceptronTagger of NLTK when evaluated on the same test sentences.\n",
    "\n",
    "**However** this should not immediately be interpreted as the spaCy tagger having poorer performance, because there is a difference in the set of Treebank tags by NLTK and spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzuEDabjd7Ey",
    "outputId": "ad591cbf-0a80-47f7-c5aa-bd8058a079bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#', '-NONE-', '-RRB-', 'LS'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set difference of NLTK Treebank tags and spaCy Treebank tags\n",
    "set(tag_list) - set([token.tag_ for token in sm_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DIIyjb-qd7E5"
   },
   "source": [
    "For this task, since the gold reference of tags is according to NLTK, spaCy's tagging will necessarily be judged 'incorrect' whenever these 4 tags are applied. Therefore no conclusion should be drawn as yet to the relative performances of NLTK and spaCy's taggers; more work needs to be done to ensure any comparison is made on an even footing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ccvLT8Tpd7E6"
   },
   "source": [
    "## Bidirectional LSTM\n",
    "\n",
    "No transfer learning applied for now. A logical next step improve the model would be to put in a pretrained Elmo embedding layer which would reduce the number of parameters that need to be trained, and only a small number left trainable for fine tuning. Some other transfer learning method using Bert / ULMFiT would also be viable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnU3V0WBd7E8"
   },
   "source": [
    "###  Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFZbOuNtd7E-"
   },
   "outputs": [],
   "source": [
    "# tagged_sentences = treebank.tagged_sents()\n",
    "sentences, sentence_tags = flatten_tagged_sentences(tagged_sentences)\n",
    "# 80:20 split\n",
    "train_sentences, test_sentences, train_tags, test_tags = \\\n",
    "                train_test_split(sentences, sentence_tags, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7AstzFzFd7FC"
   },
   "outputs": [],
   "source": [
    "# convert to integers\n",
    "word2index = get_word2index(train_sentences)\n",
    "tag2index = get_tag2index(train_tags)\n",
    "train_sentences_X = sentence2int(train_sentences, word2index)\n",
    "test_sentences_X = sentence2int(test_sentences, word2index)\n",
    "train_tags_y = tag2int(train_tags, tag2index)\n",
    "test_tags_y = tag2int(test_tags, tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHHj9X0id7FG"
   },
   "outputs": [],
   "source": [
    "# Pad sequences to maximum length of training sentences to give fixed size\n",
    "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EpLz4iXNd7FL"
   },
   "outputs": [],
   "source": [
    "train_tags_y_categorical = one_hot_encoding(train_tags_y, len(tag2index))\n",
    "test_tags_y_categorical = one_hot_encoding(test_tags_y, len(tag2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lY1Vnnend7FP"
   },
   "source": [
    "### Model building\n",
    "\n",
    "Let's build a bidirectional LSTM, no hyperparameter tuning and no transfer learning.\n",
    "\n",
    "Can you spot if this model is appropriate for the task at hand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nXePJNDd7FR"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "    model.add(Embedding(len(word2index), 64))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1027
    },
    "colab_type": "code",
    "id": "-OFQZlGQjXKM",
    "outputId": "49cc5492-d05c-4dba-c3c8-0738a2fac9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 271, 64)           648960    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 271, 256)          197632    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 271, 47)           12079     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 271, 47)           0         \n",
      "=================================================================\n",
      "Total params: 858,671\n",
      "Trainable params: 858,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2504 samples, validate on 627 samples\n",
      "Epoch 1/20\n",
      "2504/2504 [==============================] - 44s 18ms/step - loss: 1.1551 - acc: 0.8829 - val_loss: 0.3612 - val_acc: 0.9059\n",
      "Epoch 2/20\n",
      "2504/2504 [==============================] - 43s 17ms/step - loss: 0.3296 - acc: 0.9059 - val_loss: 0.3175 - val_acc: 0.9066\n",
      "Epoch 3/20\n",
      "2504/2504 [==============================] - 43s 17ms/step - loss: 0.3063 - acc: 0.9147 - val_loss: 0.3011 - val_acc: 0.9167\n",
      "Epoch 4/20\n",
      "2504/2504 [==============================] - 41s 16ms/step - loss: 0.2930 - acc: 0.9172 - val_loss: 0.2910 - val_acc: 0.9174\n",
      "Epoch 5/20\n",
      "2504/2504 [==============================] - 42s 17ms/step - loss: 0.2836 - acc: 0.9181 - val_loss: 0.2835 - val_acc: 0.9196\n",
      "Epoch 6/20\n",
      "2504/2504 [==============================] - 43s 17ms/step - loss: 0.2767 - acc: 0.9212 - val_loss: 0.2770 - val_acc: 0.9218\n",
      "Epoch 7/20\n",
      "2504/2504 [==============================] - 44s 17ms/step - loss: 0.2722 - acc: 0.9260 - val_loss: 0.2715 - val_acc: 0.9292\n",
      "Epoch 8/20\n",
      "2504/2504 [==============================] - 41s 16ms/step - loss: 0.2651 - acc: 0.9313 - val_loss: 0.2642 - val_acc: 0.9368\n",
      "Epoch 9/20\n",
      "2504/2504 [==============================] - 41s 16ms/step - loss: 0.2560 - acc: 0.9373 - val_loss: 0.2525 - val_acc: 0.9390\n",
      "Epoch 10/20\n",
      "2504/2504 [==============================] - 41s 16ms/step - loss: 0.2407 - acc: 0.9392 - val_loss: 0.2334 - val_acc: 0.9410\n",
      "Epoch 11/20\n",
      "2504/2504 [==============================] - 41s 16ms/step - loss: 0.2181 - acc: 0.9444 - val_loss: 0.2084 - val_acc: 0.9456\n",
      "Epoch 12/20\n",
      "2504/2504 [==============================] - 41s 16ms/step - loss: 0.1920 - acc: 0.9512 - val_loss: 0.1832 - val_acc: 0.9526\n",
      "Epoch 13/20\n",
      "2504/2504 [==============================] - 41s 16ms/step - loss: 0.1665 - acc: 0.9561 - val_loss: 0.1594 - val_acc: 0.9559\n",
      "Epoch 14/20\n",
      "2504/2504 [==============================] - 43s 17ms/step - loss: 0.1413 - acc: 0.9616 - val_loss: 0.1365 - val_acc: 0.9627\n",
      "Epoch 15/20\n",
      "2504/2504 [==============================] - 42s 17ms/step - loss: 0.1172 - acc: 0.9697 - val_loss: 0.1151 - val_acc: 0.9713\n",
      "Epoch 16/20\n",
      "2504/2504 [==============================] - 41s 16ms/step - loss: 0.0948 - acc: 0.9780 - val_loss: 0.0963 - val_acc: 0.9771\n",
      "Epoch 17/20\n",
      "2504/2504 [==============================] - 41s 17ms/step - loss: 0.0761 - acc: 0.9837 - val_loss: 0.0811 - val_acc: 0.9815\n",
      "Epoch 18/20\n",
      "2504/2504 [==============================] - 41s 16ms/step - loss: 0.0607 - acc: 0.9879 - val_loss: 0.0693 - val_acc: 0.9842\n",
      "Epoch 19/20\n",
      "2504/2504 [==============================] - 42s 17ms/step - loss: 0.0487 - acc: 0.9906 - val_loss: 0.0602 - val_acc: 0.9864\n",
      "Epoch 20/20\n",
      "2504/2504 [==============================] - 42s 17ms/step - loss: 0.0396 - acc: 0.9925 - val_loss: 0.0539 - val_acc: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf5df51cd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(train_sentences_X, \n",
    "          train_tags_y_categorical,\n",
    "          batch_size=64, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KmlFgKbCj1FJ"
   },
   "outputs": [],
   "source": [
    "# model.save('colab_trained_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Odi10Lnvlx5R",
    "outputId": "d8997ae8-a338-4c1f-b825-3a22416871f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 9s 12ms/step\n",
      "acc: 0.987850676475\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_sentences_X, \n",
    "                        test_tags_y_categorical)\n",
    "print(\"{}: {}\".format(model.metrics_names[1], scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cN2aFbosl323"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "The above model was trained on a GPU instance with Google Colab. The exceptionally high accuracy score beyond the reported state of the art would suggest overfitting, even though the performance evaluation is done on an unseen set.\n",
    "\n",
    "This can readily be explained by the size of the dataset:\n",
    "\n",
    "- Tagged sentences: 3914\n",
    "\n",
    "- Tagged words: 100676\n",
    "\n",
    "which is very small, versus the massive learning capacity of the bidirectional LSTM with 197632 parameters.\n",
    "\n",
    "As a general point, some measures can be taken to minimise the chances of overfitting:\n",
    "\n",
    "- specifying a smaller network to reduce capacity of learning\n",
    "\n",
    "- weight regularisation\n",
    "\n",
    "- dropout\n",
    "\n",
    "- early stopping"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ML Engineer exercise.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:streetbees]",
   "language": "python",
   "name": "conda-env-streetbees-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
